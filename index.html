<!DOCTYPE html>
<html>
<head>
    <title>Welcome to My Personal Website</title>
</head>  
<body>
    <h1>Hello, I'm Salar Shakib!</h1>
    <p>Welcome to my personal website hosted on GitHub Pages.</p>

    <!-- News Section -->
    <section id="news">
        <h2>News</h2>
        <ul>
            <li><strong>Dec 2024:</strong> Our paper, <a href="https://ieeexplore.ieee.org/abstract/document/10804123" target="_blank">E-MAC: Enhanced In-SRAM MAC Accuracy via Digital-to-Time Modulation</a>, published in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6570653" target="_blank">IEEE JXCDC</a>, explores a novel in-memory computing approach for deep learning accelerators.</li>
            <li><strong>July 2024:</strong> Our paper, <a href="https://openreview.net/pdf?id=rver7enVfY" target="_blank">An Analytical Approach to Enhancing DNN Efficiency and Accuracy Using Approximate Multiplication</a>, was presented at the <a href="https://want-ai-hpc.github.io/icml2024/about/" target="_blank">WANT Workshop at ICML 2024</a>.</li>
            <li><strong>July 2024:</strong> Our paper titled <a href="https://ieeexplore.ieee.org/document/10682772" target="_blank">Harnessing Approximate Computing for Machine Learning</a> was successfully accepted and presented at ISVLS 2024.</li>
            <li><strong>July 2024:</strong> <a href="https://dl.acm.org/doi/abs/10.1145/3649329.3661852" target="_blank">OPTIMA</a>, was presented at the DAC 2024 conference.</li>
            <li><strong>March 2024:</strong> Our survey paper, co-authored with fellow ESRs from <a href="https://projects.tuni.fi/apropos/" target="_blank">APROPOS</a>, has been successfully published in the Journal of Systems Architecture. Title: Adaptive Approximate Computing in Edge AI and IoT Applications: A Review.</li>
            <li><strong>Feb 2024:</strong> Our paper, <a href="https://ieeexplore.ieee.org/abstract/document/10457067" target="_blank">ACE-CNN: Approximate Carry Disregard Multipliers for Energy-Efficient CNN-Based Image Classification</a>, published in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8919" target="_blank">IEEE TCAS-I</a>, introduces SCDM8 multipliers, achieving energy savings with minimal accuracy loss. It studies their impact on CNNs, highlighting the efficiency-accuracy trade-offs.</li>
            <li><strong>March 2023:</strong> Check out our new pre-print on "The Role of Pre-training Data in Transfer Learning." A shorter version is accepted at the ICLR Workshop on Multimodal Representation Learning.</li>
            <li><strong>January 2023:</strong> Our REPAIR paper is accepted at ICLR 2023. This follows up on our work on permutation invariance of neural networks.</li>
            <li><strong>January 2023:</strong> As part of my internship at UW, we introduced DataComp, a new large-scale multimodal benchmark to measure the effect of data curation strategies on downstream model performance. Stay tuned!</li>
            <li><strong>January 2023:</strong> I am invited to give a talk about our recent work on permutation invariances at the MIT-IBM Watson AI Lab, IBM Research on February 2nd. Drop me an email if you'd like to attend!</li>
            <li><strong>August 2022:</strong> One paper is accepted at MICCAI 2022 Applications of Medical AI (AMAI) Workshop.</li>
            <li><strong>June 2022:</strong> Two papers are accepted at ICML 2022 Hardware Aware Efficient Training and Pre-training: Perspectives, Pitfalls, and Paths Forward workshops.</li>
            <li><strong>June 2022:</strong> I organized the 2nd Efficient Machine Learning Workshop, this time in Vienna.</li>
            <li><strong>February 2022:</strong> I will give a talk about our recent work on Permutation Invariance at the EPFL Virtual Symposium: Loss Landscape of Neural Networks.</li>
            <li><strong>January 2022:</strong> One paper is accepted at ICLR 2022 (score: 7.0, top 5%).</li>
        </ul>
    </section>
    <!-- Languages Section -->
    <section id="languages">
        <h2>Languages</h2>
        <ul>
            <li> English</li>
            <li> German </li>
            <li> Persian (Native)</li>
        </ul>
    </section>
    
</body>
</html>

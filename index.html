<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Salar Shakib</title>

    <meta name="author" content="Salar Shakib">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Salar Shakib
                </p>
                <p>    
		I am Salar Shakibhamedan, a Ph.D. candidate at <a href="https://www.tuwien.at/en/">TU Wien (Vienna University of Technology)</a>, specializing in Edge AI and efficient deep learning. 
		My research focuses on optimizing AI models for performance and scalability in resource-constrained environments. 
		Currently, I am a visiting researcher in <a href="https://healthscitech.nursing.uci.edu/">SciTech Lab</a> at <a href="https://uci.edu/">University of California, Irvine (UCI)</a>, where my work studies techniques to 
		enhance LLM usability in healthcare domain.	
                </p>
                <p style="text-align:center">
                  <a href="mailto:salar.shakib@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/My_Curriculum_Vitae__PostDoc_TU_Wien___Nov_2024_.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=LMgdVRgAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/salarshk">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
        <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>arXiv</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr>

    <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat4d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat4d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat4d_start() {
            document.getElementById('cat4d_image').style.opacity = "1";
          }

          function cat4d_stop() {
            document.getElementById('cat4d_image').style.opacity = "0";
          }
          cat4d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat-4d.github.io/">
			<span class="papertitle">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
</span>
        </a>
        <br>
				<a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
				<a href="https://poolio.github.io/">Ben Poole</a>,
				<a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
				<a href="https://www.cs.columbia.edu/~cxz/index.htm/">Changxi Zheng</a>,
				<strong>Jonathan T. Barron</strong>,
				<a href="https://holynski.org/">Aleksander Holynski</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://cat-4d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
        <p></p>
        <p>
				An approach for turning a video into a 4D radiance field that can be rendered in real-time. When combined with a text-to-video model, this enables text-to-4D.
        </p>
      </td>
    </tr>


    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
          <source src="images/r2r.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/r2r.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://relight-to-reconstruct.github.io/">
          <span class="papertitle">Generative Multiview Relighting for
3D Reconstruction under Extreme Illumination Variation</span>
        </a>
        <br>
        <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
				<strong>Jonathan T. Barron</strong>, 
        <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>, 
        <a href="https://dorverbin.github.io/">Dor Verbin</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color=#FF8080><strong>(Highlight)</strong></font>
        <br>
        <a href="https://relight-to-reconstruct.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
        <p></p>
        <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p>
      </td>
    </tr>


    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/vit_loss_landscapes_optimized.png' width=100%>
					</div>
          <img src='images/vit_loss_landscapes_optimized.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://half-potato.gitlab.io/posts/ever/">
			<span class="papertitle">Approximation Strategies for Vision Models on Edge Devices: An Accuracy-Efficiency Trade-off
</span>
        </a>
	       <br>
      <a href="https://www.tudelft.nl/en/tpm/our-faculty/departments/engineering-systems-and-services/people/phd-candidates/d-dewant-katare">Dewant Katare</a>,	      
             <strong>Salar Shakibhamedan</strong>,
      <a href="https://scholar.google.com/citations?hl=en&user=X-NAQiEAAAAJ">Nima Amirafshar</a>, <br>
      <a href="https://nima.eclectx.org/">Nima TaheriNejad</a>,
      <a href="https://jantsch.se/AxelJantsch/HomePage/index.html">Axel Jantsch</a>,
      <a href="https://scholar.google.com/citations?user=BZocCJwAAAAJ&hl=en">Marijn Janssen</a>,
      <a href="https://www.tudelft.nl/en/staff/m.f.w.h.a.janssen/?cHash=7be9122e954a868d2f8cc33e08dbb26a">Aaron Yi Ding</a>
	       <br>
        <em>TechXiv</em>, 2024
        <br>
        <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.173337762.24402407">TechXiv</a>
        <p></p>
        <p>
Efficient deployment of AI models in autonomous and edge applications requires balancing computational demands with performance. This paper proposes three approximation schemes—approximate multipliers, low-multiplicative convolution, and variational inference with quantization—that collectively address this challenge across CNNs, DNNs, and especially Vision Transformers. By integrating these techniques, the study achieves substantial reductions in energy consumption and model size while maintaining accuracy close to baseline levels. The results highlight the potential of approximate computing as a viable strategy for enabling high-performance Vision Transformers and other models in resource-constrained environments.
	</p>
      </td>
    </tr>

    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
          <source src="images/IBTrain.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/IBTrain.png' width=100%>
        </div>
        <script type="text/javascript">
          function smerf_start() {
            document.getElementById('smerf_image').style.opacity = "1";
          }

          function smerf_stop() {
            document.getElementById('smerf_image').style.opacity = "0";
          }
          smerf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://smerf-3d.github.io/">
          <span class="papertitle">An Analytical Approach to Enhancing DNN Efficiency and Accuracy Using
Approximate Multiplication</span>
        </a>
        <br>
      <strong>Salar Shakibhamedan</strong>,
      <a href="https://scholar.google.com/citations?user=TnTONnkAAAAJ&hl=en">Anice Jahanjoo</a>,
      <a href="https://aminaminifar.github.io/info/">Amin Aminifar</a>,
      <a href="https://scholar.google.com/citations?hl=en&user=X-NAQiEAAAAJ">Nima Amirafshar</a>, <br>
      <a href="https://nima.eclectx.org/">Nima TaheriNejad</a>,
      <a href="https://jantsch.se/AxelJantsch/HomePage/index.html">Axel Jantsch</a>
        <br>
        <a href="https://want-ai-hpc.github.io/icml2024/about/">ICML Workshop on Advancing Neural Network Training: Computational Efficiency, Scalability, and Resource Optimization, 2024</a>
        <br>
        <a href="https://openreview.net/pdf?id=rver7enVfY">Paper</a>
        <p></p>
        <p>
        Optimization and approximation techniques are commonly used to improve the efficiency of DNNs, but they often come at the cost of reduced performance. This paper introduces a novel approach that achieves both efficiency and performance improvement simultaneously through approximation. By leveraging Information Bottleneck theory, the work provides the first formal connection between efficiency techniques and information-theoretic analysis, using the information plane to study how approximation affects the learning behavior of DNNs.
        </p>
      </td>
    </tr>
	



  <tr onmouseout="eclipse_stop()" onmouseover="eclipse_start()">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='eclipse_image'><video  width=100% height=100% muted autoplay loop>
        <source src="images/Approx_Conv_page-0001.jpg" type="video/mp4">
        Your browser does not support the video tag.
        </video></div>
        <img src='images/Approx_Conv_page-0001.jpg' width="160">
      </div>
      <script type="text/javascript">
        function eclipse_start() {
          document.getElementById('eclipse_image').style.opacity = "1";
        }

        function eclipse_stop() {
          document.getElementById('eclipse_image').style.opacity = "0";
        }
        eclipse_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://dorverbin.github.io/eclipse">
        <span class="papertitle">
ACE-CNN: Approximate Carry Disregard Multipliers for Energy-Efficient CNN-Based Image Classification</span>
      </a>
      <br>
      <strong>Salar Shakibhamedan</strong>,
      <a href="https://scholar.google.com/citations?hl=en&user=X-NAQiEAAAAJ">Nima Amirafshar</a>,
      <a href="https://www.sfu.ca/~asa582/">Ahmad Sedigh Baroughi</a>, 
      <a href="https://www.iust.ac.ir/content/8843/Dr.shahhosseini">Hadi Shahriar Shahhoseini</a>,<br>
      <a href="https://nima.eclectx.org/">Nima TaheriNejad</a>
      <br>
      <em>IEEE Transaction (TCAS-I)</em>, 2024 &nbsp <font color="red"><strong></strong></font>
      <br>
      <a href="https://ieeexplore.ieee.org/abstract/document/10457067">Paper</a>
      <p></p>
      <p>
CNNs are powerful but resource-intensive, making them challenging to deploy on edge and power-constrained devices. This paper introduces a novel family of approximate multipliers that reduce energy and delay while maintaining strong machine learning performance. It presents the first comprehensive study to demonstrate improvements in both computational efficiency and model accuracy, enabling practical, high-performance CNNs for resource-limited environments.
      </p>
    </td>
  </tr>


          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
